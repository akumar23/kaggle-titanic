{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.ensemble import RandomForestClassifier\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-25T03:37:31.330795Z","iopub.execute_input":"2022-07-25T03:37:31.331411Z","iopub.status.idle":"2022-07-25T03:37:32.685102Z","shell.execute_reply.started":"2022-07-25T03:37:31.331376Z","shell.execute_reply":"2022-07-25T03:37:32.683676Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Intro\n\nAfter importing the basic libraries needed I like to start the analysis of the data by declaring variables that read the csv files for train and test data. I also like to print out the head of both along with the info to get a quick overview of what I'm working with.","metadata":{}},{"cell_type":"code","source":"#asign variables to train and test data\n#and print out their info to get an idea of what they contain\n\ntrain_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\nprint(train_data.head())\n\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\nprint(test_data.head())\n\ntrain_data['train_test'] = 1\ntest_data['train_test'] = 0\n\ntrain_data.info()\ntest_data.info()\n\n","metadata":{"execution":{"iopub.status.busy":"2022-07-25T03:37:34.582752Z","iopub.execute_input":"2022-07-25T03:37:34.583519Z","iopub.status.idle":"2022-07-25T03:37:34.665996Z","shell.execute_reply.started":"2022-07-25T03:37:34.583484Z","shell.execute_reply":"2022-07-25T03:37:34.664901Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#more analysis of the training data\ntrain_data.describe()","metadata":{"execution":{"iopub.status.busy":"2022-07-24T20:11:52.832276Z","iopub.execute_input":"2022-07-24T20:11:52.833024Z","iopub.status.idle":"2022-07-24T20:11:52.876681Z","shell.execute_reply.started":"2022-07-24T20:11:52.832985Z","shell.execute_reply":"2022-07-24T20:11:52.875490Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#breaking up training data into numeric and catagorical variables\n\nnumeric_train = train_data[['Age', 'SibSp', 'Parch', 'Fare']]\ncatagoric_train = train_data[['Survived', 'Pclass', 'Sex', 'Ticket', 'Cabin', 'Embarked']]\n \n#create a heatmap for how each variable correlates with each other\ncorreleate = numeric_train.corr()\nprint(correleate)\nsns.heatmap(correleate)","metadata":{"execution":{"iopub.status.busy":"2022-07-24T20:11:54.466864Z","iopub.execute_input":"2022-07-24T20:11:54.467298Z","iopub.status.idle":"2022-07-24T20:11:54.725160Z","shell.execute_reply.started":"2022-07-24T20:11:54.467262Z","shell.execute_reply":"2022-07-24T20:11:54.724072Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering\n\n1. Analyze how family size effected survival rate and the average age of survivors\n\n2. Check how many people had multiple cabins and if that impacted survival rates\n\n3. See how ticket types had an impact on survival rates","metadata":{}},{"cell_type":"code","source":"#creating table to see the average age of survivors and family size\npd.pivot_table(train_data, index = 'Survived', values = ['Age', 'SibSp'])","metadata":{"execution":{"iopub.status.busy":"2022-07-24T20:11:56.778877Z","iopub.execute_input":"2022-07-24T20:11:56.779262Z","iopub.status.idle":"2022-07-24T20:11:56.805196Z","shell.execute_reply.started":"2022-07-24T20:11:56.779232Z","shell.execute_reply":"2022-07-24T20:11:56.804283Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"catagoric_train.Cabin\ntrain_data['cabin_multiple'] = train_data.Cabin.apply(lambda x:0 if pd.isna(x) else len(x.split(' ')))\n\ntrain_data['cabin_multiple'].value_counts()\n\npd.pivot_table(train_data, index = 'Survived', columns = 'cabin_multiple', \n               values = 'Ticket' , aggfunc = 'count')","metadata":{"execution":{"iopub.status.busy":"2022-07-24T20:11:58.565161Z","iopub.execute_input":"2022-07-24T20:11:58.566189Z","iopub.status.idle":"2022-07-24T20:11:58.597786Z","shell.execute_reply.started":"2022-07-24T20:11:58.566151Z","shell.execute_reply":"2022-07-24T20:11:58.595934Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#compares survival rates over cabins, n means cabin was null in dataset \ntrain_data['cabin_adv'] = train_data.Cabin.apply(lambda x: str(x)[0])\n\nprint(train_data.cabin_adv.value_counts())\npd.pivot_table(train_data, index='Survived', columns='cabin_adv', \n               values = 'Name', aggfunc='count')","metadata":{"execution":{"iopub.status.busy":"2022-07-24T20:12:00.214712Z","iopub.execute_input":"2022-07-24T20:12:00.215130Z","iopub.status.idle":"2022-07-24T20:12:00.248023Z","shell.execute_reply.started":"2022-07-24T20:12:00.215094Z","shell.execute_reply":"2022-07-24T20:12:00.247174Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train_data['numeric_ticket'] = train_data.Ticket.apply(lambda x:1 if x.isnumeric() else 0)\n\n\npd.pivot_table(train_data, index='Survived', columns='numeric_ticket', \n               values = 'Ticket', aggfunc = 'count')","metadata":{"execution":{"iopub.status.busy":"2022-07-24T20:12:02.261523Z","iopub.execute_input":"2022-07-24T20:12:02.262366Z","iopub.status.idle":"2022-07-24T20:12:02.284847Z","shell.execute_reply.started":"2022-07-24T20:12:02.262331Z","shell.execute_reply":"2022-07-24T20:12:02.284066Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_data['cabin_adv'] = train_data.Cabin.apply(lambda x: str(x)[0])\n\npd.pivot_table(train_data,index='Survived',columns='cabin_adv', \n               values = 'Name', aggfunc='count')","metadata":{"execution":{"iopub.status.busy":"2022-07-24T20:12:04.121873Z","iopub.execute_input":"2022-07-24T20:12:04.122455Z","iopub.status.idle":"2022-07-24T20:12:04.150993Z","shell.execute_reply.started":"2022-07-24T20:12:04.122424Z","shell.execute_reply":"2022-07-24T20:12:04.149778Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing for Model\n\n1. Use only relevant variables \n\n2. Get our training and test data to have the same columns\n\n3. Add any null values we find with a randomization of the mean +/- standarad deviation or median\n\n4. Normalize fare data value \n\n5. Then split train and test values of x and y","metadata":{}},{"cell_type":"code","source":"#combine all data\nall_data = pd.concat([train_data, test_data])\n\n#place values where they might be missing\nall_data['cabin_multiple'] = all_data.Cabin.apply(lambda x: 0 if pd.isna(x) \n                                                  else len(x.split(' ')))\n\nall_data['cabin_adv'] = all_data.Cabin.apply(lambda x: str(x)[0])\nall_data['numeric_ticket'] = all_data.Ticket.apply(lambda x: 1 if x.isnumeric() else 0)\nall_data['ticket_letters'] = all_data.Ticket.apply(lambda x: \n                                                   ''.join(x.split(' ')[:-1]).replace('.','')\n                                                   .replace('/','').lower() \n                                                   if len(x.split(' ')[:-1]) >0 else 0)\n\nall_data.Age = all_data.Age.fillna(train_data.Age.median())\nall_data.Fare = all_data.Fare.fillna(train_data.Fare.median())\n\nall_data['norm_fare'] = np.log(all_data.Fare+1)\nall_data['norm_fare'].hist()\n\nall_dummies = pd.get_dummies(all_data[['Pclass','Sex','Age','Parch','norm_fare',\n                                        'cabin_adv','cabin_multiple',\n                                       'numeric_ticket', 'train_test']])\n\n#split to train for x and y and test for x now that the data is updated\nX_train = all_dummies[all_dummies.train_test == 1].drop(['train_test'], axis =1)\nX_test = all_dummies[all_dummies.train_test == 0].drop(['train_test'], axis =1)\n\ny_train = all_data[all_data.train_test==1].Survived","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscale = StandardScaler()\nall_dummies_scaled = all_dummies.copy()\nall_dummies_scaled[['Age', 'Parch', 'norm_fare']] = scale.fit_transform (all_dummies_scaled[['Age', 'Parch', 'norm_fare']])\n\nX_train_scaled = all_dummies_scaled[all_dummies_scaled.train_test == 1].drop(['train_test'], \n                                                                             axis =1)\n\nX_test_scaled = all_dummies_scaled[all_dummies_scaled.train_test == 0].drop(['train_test'],\n                                                                           axis =1)\ny_train = all_data[all_data.train_test==1].Survived","metadata":{"execution":{"iopub.status.busy":"2022-07-24T21:11:56.868507Z","iopub.execute_input":"2022-07-24T21:11:56.869317Z","iopub.status.idle":"2022-07-24T21:11:56.886305Z","shell.execute_reply.started":"2022-07-24T21:11:56.869281Z","shell.execute_reply":"2022-07-24T21:11:56.885392Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"# **Model Building**\n\nGoing to test multiple models to see which one works best for this specific data set.\nJust because one model tends to produce the best results that doesn't mean that it will always be that way for all possible data sets.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import tree\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\n\ngnb = GaussianNB()\ncv = cross_val_score(gnb, X_train_scaled, y_train, cv=5)\n\nprint(\"Testing Naive Bayes:\")\nprint(cv)\nprint(cv.mean(),\"\\n\")\n\nlr = LogisticRegression(max_iter = 2000)\ncv = cross_val_score(lr, X_train, y_train, cv=5)\n\nprint(\"Testing Logistic Regression:\")\nprint(cv)\nprint(cv.mean(),\"\\n\")\n\ndt = tree.DecisionTreeClassifier(random_state = 1)\ncv = cross_val_score(dt,X_train_scaled,y_train,cv=5)\n\nprint(\"Testing Decision Tree Classifier:\")\nprint(cv)\nprint(cv.mean(),\"\\n\")\n\n\nknn = KNeighborsClassifier()\ncv = cross_val_score(knn,X_train_scaled,y_train,cv=5)\n\nprint(\"Testing K Neighbor Classifier:\")\nprint(cv)\nprint(cv.mean(),\"\\n\")\n\n\nsvc = SVC(probability = True)\ncv = cross_val_score(svc,X_train_scaled,y_train,cv=5)\n\nprint(\"Testing SVC:\")\nprint(cv)\nprint(cv.mean(),\"\\n\")\n\nrf = RandomForestClassifier()\ncv = cross_val_score(rf, X_train_scaled, y_train, cv=5)\n\nprint(\"Testing Random Forest:\")\nprint(cv)\nprint(cv.mean(),\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-07-24T21:33:33.616958Z","iopub.execute_input":"2022-07-24T21:33:33.617971Z","iopub.status.idle":"2022-07-24T21:33:36.196210Z","shell.execute_reply.started":"2022-07-24T21:33:33.617930Z","shell.execute_reply":"2022-07-24T21:33:36.195064Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV \nfrom sklearn.model_selection import RandomizedSearchCV \n\n#function to get best score and best parameters for a training model\ndef clf_performance(classifier, model_name):\n    print(model_name)\n    print('Best Score: ' + str(classifier.best_score_))\n    print('Best Parameters: ' + str(classifier.best_params_))\n    \n\n#testing K Neighbors Classifier\nknn = KNeighborsClassifier()\nparam_grid = {'n_neighbors' : [3,5,7,9],\n              'weights' : ['uniform', 'distance'],\n              'algorithm' : ['auto', 'ball_tree','kd_tree'],\n              'p' : [1,2]}\nclf_knn = GridSearchCV(knn, param_grid = param_grid, cv = 5, verbose = True, n_jobs = -1)\nbest_clf_knn = clf_knn.fit(X_train_scaled,y_train)\nclf_performance(best_clf_knn,'KNN')","metadata":{"execution":{"iopub.status.busy":"2022-07-24T21:31:30.910261Z","iopub.execute_input":"2022-07-24T21:31:30.910702Z","iopub.status.idle":"2022-07-24T21:31:33.645236Z","shell.execute_reply.started":"2022-07-24T21:31:30.910663Z","shell.execute_reply":"2022-07-24T21:31:33.643729Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"#testing SVC\nsvc = SVC(probability = True)\nparam_grid = tuned_parameters = [{'kernel': ['rbf'], 'gamma': [.1,.5,1,2,5,10],\n                                  'C': [.1, 1, 10, 100, 1000]},\n                                 {'kernel': ['linear'], 'C': [.1, 1, 10, 100, 1000]},\n                                 {'kernel': ['poly'], 'degree' : [2,3,4,5], 'C': [.1, 1, 10, 100, 1000]}]\nclf_svc = GridSearchCV(svc, param_grid = param_grid, cv = 5, verbose = True, n_jobs = -1)\nbest_clf_svc = clf_svc.fit(X_train_scaled,y_train)\nclf_performance(best_clf_svc,'SVC')","metadata":{"execution":{"iopub.status.busy":"2022-07-24T21:51:18.128609Z","iopub.execute_input":"2022-07-24T21:51:18.129041Z","iopub.status.idle":"2022-07-24T21:58:38.823836Z","shell.execute_reply.started":"2022-07-24T21:51:18.129007Z","shell.execute_reply":"2022-07-24T21:58:38.822517Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"#testing random forest\nrf = RandomForestClassifier(random_state = 1)\nparam_grid =  {'n_estimators': [400,450,500,550],\n               'criterion':['gini','entropy'],\n                                  'bootstrap': [True],\n                                  'max_depth': [15, 20, 25],\n                                  'max_features': ['auto','sqrt', 10],\n                                  'min_samples_leaf': [2,3],\n                                  'min_samples_split': [2,3]}\n                                  \nclf_rf = GridSearchCV(rf, param_grid = param_grid, cv = 5, verbose = True, n_jobs = -1)\nbest_clf_rf = clf_rf.fit(X_train_scaled,y_train)\nclf_performance(best_clf_rf,'Random Forest')","metadata":{"execution":{"iopub.status.busy":"2022-07-24T21:38:45.687011Z","iopub.execute_input":"2022-07-24T21:38:45.687763Z","iopub.status.idle":"2022-07-24T21:48:48.244964Z","shell.execute_reply.started":"2022-07-24T21:38:45.687727Z","shell.execute_reply":"2022-07-24T21:48:48.243651Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"best_rf = best_clf_rf.best_estimator_.fit(X_train_scaled,y_train)\nfeat_importances = pd.Series(best_rf.feature_importances_, index=X_train_scaled.columns)\nfeat_importances.nlargest(20).plot(kind='barh')","metadata":{"execution":{"iopub.status.busy":"2022-07-24T22:11:31.395817Z","iopub.execute_input":"2022-07-24T22:11:31.396207Z","iopub.status.idle":"2022-07-24T22:11:32.530499Z","shell.execute_reply.started":"2022-07-24T22:11:31.396166Z","shell.execute_reply":"2022-07-24T22:11:32.529645Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"# Final Submission\n\n1. Did voting hard and soft for (KNN, RF and SVC)\n2. Finalized the final data\n3. Placed that data into a dataframe\n4. Submitted the final answer","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier\n\nbest_knn = best_clf_knn.best_estimator_\nbest_svc = best_clf_svc.best_estimator_\nbest_rf = best_clf_rf.best_estimator_\n\nvoting_clf_hard = VotingClassifier(estimators = [('knn',best_knn),('rf',best_rf),('svc',best_svc)], voting = 'hard')  \nvoting_clf_all = VotingClassifier(estimators = [('knn',best_knn),('rf',best_rf),('svc',best_svc)], voting = 'soft') \nvoting_clf_soft = VotingClassifier(estimators = [('knn',best_knn),('rf',best_rf),('svc',best_svc)], voting = 'soft') \n\n\nprint('voting_clf_hard :',cross_val_score(voting_clf_hard,X_train,y_train,cv=5))\nprint('voting_clf_hard mean :',cross_val_score(voting_clf_hard,X_train,y_train,cv=5).mean())\n\nprint('voting_clf_soft :',cross_val_score(voting_clf_soft,X_train,y_train,cv=5))\nprint('voting_clf_soft mean :',cross_val_score(voting_clf_soft,X_train,y_train,cv=5).mean())\n\nprint('voting_clf_all :',cross_val_score(voting_clf_all,X_train,y_train,cv=5))\nprint('voting_clf_all mean :',cross_val_score(voting_clf_all,X_train,y_train,cv=5).mean())","metadata":{"execution":{"iopub.status.busy":"2022-07-24T22:15:43.293293Z","iopub.execute_input":"2022-07-24T22:15:43.293718Z","iopub.status.idle":"2022-07-24T22:17:14.018575Z","shell.execute_reply.started":"2022-07-24T22:15:43.293680Z","shell.execute_reply":"2022-07-24T22:17:14.017283Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"#making the predictions\nvoting_clf_hard.fit(X_train_scaled, y_train)\nvoting_clf_soft.fit(X_train_scaled, y_train)\nvoting_clf_all.fit(X_train_scaled, y_train)\n\nbest_rf.fit(X_train_scaled, y_train)\ny_hat_vc_hard = voting_clf_hard.predict(X_test_scaled).astype(int)\ny_hat_rf = best_rf.predict(X_test_scaled).astype(int)\ny_hat_vc_soft =  voting_clf_soft.predict(X_test_scaled).astype(int)\ny_hat_vc_all = voting_clf_all.predict(X_test_scaled).astype(int)","metadata":{"execution":{"iopub.status.busy":"2022-07-24T22:21:41.005924Z","iopub.execute_input":"2022-07-24T22:21:41.006342Z","iopub.status.idle":"2022-07-24T22:22:12.931686Z","shell.execute_reply.started":"2022-07-24T22:21:41.006310Z","shell.execute_reply":"2022-07-24T22:22:12.930654Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"#Updating final data and building the submissions with the predictions made\nfinal_data = {'PassengerId': test_data.PassengerId, 'Survived': y_hat_vc_all}\nsubmission = pd.DataFrame(data=final_data)\n\n#submitting all the final submissions\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-07-24T22:24:01.089876Z","iopub.execute_input":"2022-07-24T22:24:01.090301Z","iopub.status.idle":"2022-07-24T22:24:01.113744Z","shell.execute_reply.started":"2022-07-24T22:24:01.090266Z","shell.execute_reply":"2022-07-24T22:24:01.112729Z"},"trusted":true},"execution_count":57,"outputs":[]}]}